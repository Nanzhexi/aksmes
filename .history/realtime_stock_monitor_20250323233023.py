import streamlit as st
import pandas as pd
import numpy as np
import time
import requests
import json
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import akshare as ak

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="è‚¡ç¥¨å®æ—¶ç›‘æ§", page_icon="ğŸ“ˆ", layout="wide")

# é¡µé¢æ ‡é¢˜
st.title("è‚¡ç¥¨å®æ—¶è¡Œæƒ…ä¸èµ„é‡‘æµå‘ç›‘æ§")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("è®¾ç½®")
    stock_code = st.text_input("è‚¡ç¥¨ä»£ç ", "600519")
    
    # æ·»åŠ å¸‚åœºé€‰æ‹©
    market = st.selectbox("é€‰æ‹©å¸‚åœº", ["ä¸Šæµ·", "æ·±åœ³"], index=0)
    
    # æ›´æ–°é¢‘ç‡è®¾ç½®
    update_interval = st.slider("æ›´æ–°é¢‘ç‡(ç§’)", min_value=6, max_value=60, value=6, step=1)
    
    # æ•°æ®å±•ç¤ºæ—¶é•¿è®¾ç½®
    display_minutes = st.slider("å›¾è¡¨æ˜¾ç¤ºæ—¶é•¿(åˆ†é’Ÿ)", min_value=10, max_value=120, value=30, step=5)
    
    # è¿è¡Œæ§åˆ¶
    is_running = st.checkbox("å¼€å§‹ç›‘æ§", value=True)
    clear_data = st.button("æ¸…ç©ºå†å²æ•°æ®")

# æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼å¹¶æ ‡å‡†åŒ–
def normalize_stock_code(code, market="ä¸Šæµ·"):
    code = code.strip()
    
    # å¦‚æœåªæœ‰æ•°å­—ï¼Œæ·»åŠ å¸‚åœºå‰ç¼€
    if code.isdigit():
        if market == "ä¸Šæµ·":
            if code.startswith("6"):
                return f"sh{code}"
            else:
                return f"sh{code}"  # é»˜è®¤ä½¿ç”¨ä¸Šæµ·
        else:  # æ·±åœ³
            if code.startswith(("0", "3")):
                return f"sz{code}"
            else:
                return f"sz{code}"  # é»˜è®¤ä½¿ç”¨æ·±åœ³
    
    # å¦‚æœå·²ç»æœ‰å‰ç¼€ï¼Œæ ‡å‡†åŒ–æ ¼å¼
    if code.lower().startswith(("sh", "sz", "bj")):
        return code.lower()
    
    return f"sh{code}"  # é»˜è®¤è¿”å›ä¸Šæµ·å¸‚åœº

# è·å–ä¸œæ–¹è´¢å¯Œå®æ—¶è‚¡ç¥¨æ•°æ®
def get_eastmoney_realtime_quote(stock_code):
    normalized_code = normalize_stock_code(stock_code, market)
    
    # æ„å»ºä¸œæ–¹è´¢å¯Œå®æ—¶è¡Œæƒ…APIçš„URL
    url = f"http://push2.eastmoney.com/api/qt/stock/get"
    
    params = {
        "secid": normalized_code,
        "ut": "fa5fd1943c7b386f172d6893dbfba10b",
        "fields": "f43,f44,f45,f46,f47,f48,f49,f50,f51,f52,f57,f58,f59,f60,f107,f111,f60,f46,f45,f47,f168,f169,f170,f85,f84",
        "invt": "2",
        "fltt": "2",
        "_": int(time.time() * 1000)
    }
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        data = response.json()
        
        if 'data' in data:
            return data['data']
        else:
            st.error(f"è·å–è¡Œæƒ…æ•°æ®å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return None
    except Exception as e:
        st.error(f"è¯·æ±‚è¡Œæƒ…æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return None

# è·å–ä¸œæ–¹è´¢å¯Œèµ„é‡‘æµå‘æ•°æ®
def get_eastmoney_capital_flow(stock_code):
    normalized_code = normalize_stock_code(stock_code, market)
    
    # æ„å»ºèµ„é‡‘æµå‘APIçš„URL
    url = f"http://push2.eastmoney.com/api/qt/stock/fflow/kline/get"
    
    params = {
        "secid": normalized_code,
        "fields1": "f1,f2,f3,f7",
        "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61,f62,f63",
        "klt": "1",  # 1åˆ†é’Ÿ
        "fqt": "0",
        "lmt": "60",  # æœ€è¿‘60æ¡æ•°æ®
        "_": int(time.time() * 1000)
    }
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        if 'data' in data and data['data'] is not None:
            return data['data']
        else:
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–èµ„é‡‘æµå‘
            try:
                # æ„å»ºå¤‡ç”¨API URL
                backup_url = f"http://push2his.eastmoney.com/api/qt/stock/fflow/daykline/get"
                backup_params = {
                    "secid": normalized_code,
                    "fields1": "f1,f2,f3,f7",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
                    "klt": "101",  # æ—¥K
                    "lmt": "10",  # æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                    "_": int(time.time() * 1000)
                }
                
                backup_response = requests.get(backup_url, params=backup_params)
                backup_response.raise_for_status()
                backup_data = backup_response.json()
                
                if 'data' in backup_data and backup_data['data'] is not None:
                    st.info("ä½¿ç”¨æ—¥çº§åˆ«èµ„é‡‘æµå‘æ•°æ®ä½œä¸ºå¤‡ç”¨")
                    return backup_data['data']
                else:
                    st.error(f"è·å–èµ„é‡‘æµå‘æ•°æ®å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return None
            except Exception as e:
                st.error(f"å¤‡ç”¨èµ„é‡‘æµå‘æ•°æ®è·å–å¤±è´¥: {str(e)}")
                return None
    except Exception as e:
        st.error(f"è¯·æ±‚èµ„é‡‘æµå‘æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return None

# ä½¿ç”¨akshareè·å–è‚¡ç¥¨åç§°
@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
def get_stock_name(stock_code):
    try:
        # å°è¯•ä½¿ç”¨akshareè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info = ak.stock_individual_info_em(symbol=stock_code)
        if stock_info is not None and not stock_info.empty:
            for index, row in stock_info.iterrows():
                if 'è‚¡ç¥¨ç®€ç§°' in row['item']:
                    return row['value']
        
        # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä»è‚¡ç¥¨åˆ—è¡¨ä¸­è·å–
        stock_list = ak.stock_zh_a_spot_em()
        if stock_list is not None and not stock_list.empty:
            filtered = stock_list[stock_list['ä»£ç '] == stock_code]
            if not filtered.empty:
                return filtered.iloc[0]['åç§°']
        
        return stock_code  # å¦‚æœæ‰¾ä¸åˆ°åç§°ï¼Œè¿”å›ä»£ç ä½œä¸ºåç§°
    except Exception as e:
        st.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
        return stock_code

# å¤„ç†å®æ—¶è¡Œæƒ…æ•°æ®
def process_quote_data(quote_data):
    if not quote_data:
        return None
    
    # æå–æ‰€éœ€çš„å­—æ®µ
    processed_data = {
        'timestamp': datetime.now(),
        'price': quote_data.get('f43', 0) / 100 if quote_data.get('f43') else 0,  # å½“å‰ä»·æ ¼
        'change': quote_data.get('f169', 0) / 100 if quote_data.get('f169') else 0,  # æ¶¨è·Œé¢
        'change_percent': quote_data.get('f170', 0) / 100 if quote_data.get('f170') else 0,  # æ¶¨è·Œå¹…
        'volume': quote_data.get('f47', 0) / 100 if quote_data.get('f47') else 0,  # æˆäº¤é‡
        'amount': quote_data.get('f48', 0) / 10000 if quote_data.get('f48') else 0,  # æˆäº¤é¢(ä¸‡å…ƒ)
        'open': quote_data.get('f46', 0) / 100 if quote_data.get('f46') else 0,  # å¼€ç›˜ä»·
        'high': quote_data.get('f44', 0) / 100 if quote_data.get('f44') else 0,  # æœ€é«˜ä»·
        'low': quote_data.get('f45', 0) / 100 if quote_data.get('f45') else 0,  # æœ€ä½ä»·
    }
    
    return processed_data

# å¤„ç†èµ„é‡‘æµå‘æ•°æ®
def process_flow_data(flow_data):
    if not flow_data or 'klines' not in flow_data:
        # å°è¯•å¤„ç†å¤‡ç”¨æ ¼å¼
        if flow_data and 'klines' not in flow_data and 'kline' in flow_data:
            flow_data['klines'] = flow_data['kline']
        else:
            return None
    
    if not flow_data['klines'] or len(flow_data['klines']) == 0:
        return None
    
    # è·å–æœ€æ–°çš„èµ„é‡‘æµå‘æ•°æ®
    latest_data = flow_data['klines'][-1].split(',')
    
    if len(latest_data) >= 7:  # ä¿®æ”¹è¿™é‡Œä»¥é€‚åº”ä¸åŒçš„æ•°æ®æ ¼å¼
        try:
            processed_data = {
                'timestamp': datetime.now(),
                'main_net_inflow': float(latest_data[1]) if latest_data[1] != '-' else 0,  # ä¸»åŠ›å‡€æµå…¥
                'retail_net_inflow': float(latest_data[2]) if latest_data[2] != '-' else 0,  # æ•£æˆ·å‡€æµå…¥
                'super_large_net_inflow': float(latest_data[3]) if latest_data[3] != '-' else 0,  # è¶…å¤§å•å‡€æµå…¥
                'large_net_inflow': float(latest_data[4]) if latest_data[4] != '-' else 0,  # å¤§å•å‡€æµå…¥
                'medium_net_inflow': float(latest_data[5]) if latest_data[5] != '-' else 0,  # ä¸­å•å‡€æµå…¥
                'small_net_inflow': float(latest_data[6]) if latest_data[6] != '-' else 0,  # å°å•å‡€æµå…¥
            }
            
            return processed_data
        except Exception as e:
            st.warning(f"å¤„ç†èµ„é‡‘æµå‘æ•°æ®å‡ºé”™: {str(e)}")
            # å°è¯•åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            return {
                'timestamp': datetime.now(),
                'main_net_inflow': 0,
                'retail_net_inflow': 0,
                'super_large_net_inflow': 0,
                'large_net_inflow': 0,
                'medium_net_inflow': 0,
                'small_net_inflow': 0,
            }
    
    return None

# åˆå§‹åŒ–æˆ–è·å–å†å²æ•°æ®
def get_historical_data():
    if 'price_history' not in st.session_state or clear_data:
        st.session_state.price_history = pd.DataFrame(columns=[
            'timestamp', 'price', 'change', 'change_percent', 'volume', 'amount', 'open', 'high', 'low'
        ])
    
    if 'flow_history' not in st.session_state or clear_data:
        st.session_state.flow_history = pd.DataFrame(columns=[
            'timestamp', 'main_net_inflow', 'retail_net_inflow', 'super_large_net_inflow', 
            'large_net_inflow', 'medium_net_inflow', 'small_net_inflow'
        ])
    
    return st.session_state.price_history, st.session_state.flow_history

# æ›´æ–°å†å²æ•°æ®
def update_historical_data(price_data, flow_data):
    # è·å–ç°æœ‰å†å²æ•°æ®
    price_history, flow_history = get_historical_data()
    
    # æ·»åŠ æ–°çš„ä»·æ ¼æ•°æ®
    if price_data:
        price_history = pd.concat([
            price_history, 
            pd.DataFrame([price_data])
        ], ignore_index=True)
    
    # æ·»åŠ æ–°çš„èµ„é‡‘æµå‘æ•°æ®
    if flow_data:
        flow_history = pd.concat([
            flow_history, 
            pd.DataFrame([flow_data])
        ], ignore_index=True)
    
    # æ¸…ç†è¿‡æ—§çš„æ•°æ®
    now = datetime.now()
    cutoff_time = now - timedelta(minutes=display_minutes)
    
    price_history = price_history[price_history['timestamp'] >= cutoff_time]
    flow_history = flow_history[flow_history['timestamp'] >= cutoff_time]
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.price_history = price_history
    st.session_state.flow_history = flow_history
    
    return price_history, flow_history

# åˆ›å»ºè‚¡ä»·èµ°åŠ¿å›¾è¡¨
def create_price_chart(price_history):
    if price_history.empty:
        return go.Figure()
    
    # åˆ›å»ºåŒ…å«ä¸¤ä¸ªå­å›¾çš„ç»„åˆå›¾è¡¨(è‚¡ä»·å’Œæˆäº¤é‡)
    fig = make_subplots(rows=2, cols=1, 
                         shared_xaxes=True, 
                         vertical_spacing=0.1, 
                         row_heights=[0.7, 0.3],
                         subplot_titles=("è‚¡ä»·èµ°åŠ¿", "æˆäº¤é‡"))
    
    # æ·»åŠ èœ¡çƒ›å›¾
    fig.add_trace(
        go.Candlestick(
            x=price_history['timestamp'],
            open=price_history['open'],
            high=price_history['high'],
            low=price_history['low'],
            close=price_history['price'],
            name="è‚¡ä»·"
        ),
        row=1, col=1
    )
    
    # æ·»åŠ æˆäº¤é‡æŸ±çŠ¶å›¾
    colors = ['red' if x >= 0 else 'green' for x in price_history['change']]
    fig.add_trace(
        go.Bar(
            x=price_history['timestamp'],
            y=price_history['volume'],
            name="æˆäº¤é‡",
            marker_color=colors
        ),
        row=2, col=1
    )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title="å®æ—¶è‚¡ä»·èµ°åŠ¿å›¾",
        height=600,
        xaxis_rangeslider_visible=False,
        xaxis=dict(
            rangebreaks=[
                dict(bounds=["sat", "mon"]),  # éšè—å‘¨æœ«
                dict(bounds=[16, 9], pattern="hour")  # éšè—éäº¤æ˜“æ—¶é—´
            ]
        )
    )
    
    # æ›´æ–°yè½´æ ‡é¢˜
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
    fig.update_yaxes(title_text="æˆäº¤é‡", row=2, col=1)
    
    return fig

# åˆ›å»ºèµ„é‡‘æµå‘å›¾è¡¨
def create_flow_chart(flow_history):
    if flow_history.empty:
        return go.Figure()
    
    # åˆ›å»ºåŒ…å«ä¸¤ä¸ªå­å›¾çš„ç»„åˆå›¾è¡¨
    fig = make_subplots(rows=2, cols=1, 
                        shared_xaxes=True, 
                        vertical_spacing=0.1,
                        row_heights=[0.5, 0.5],
                        subplot_titles=("ä¸»åŠ›vsæ•£æˆ·èµ„é‡‘å‡€æµå…¥", "å¤§ä¸­å°å•èµ„é‡‘æµå‘"))
    
    # æ·»åŠ ä¸»åŠ›å’Œæ•£æˆ·å‡€æµå…¥æŠ˜çº¿å›¾
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['main_net_inflow'],
            mode='lines',
            name="ä¸»åŠ›å‡€æµå…¥",
            line=dict(color='red')
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['retail_net_inflow'],
            mode='lines',
            name="æ•£æˆ·å‡€æµå…¥",
            line=dict(color='blue')
        ),
        row=1, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_trace(
        go.Scatter(
            x=[flow_history['timestamp'].min(), flow_history['timestamp'].max()],
            y=[0, 0],
            mode='lines',
            line=dict(color='black', dash='dash'),
            name="é›¶çº¿",
            showlegend=False
        ),
        row=1, col=1
    )
    
    # æ·»åŠ å¤§ä¸­å°å•èµ„é‡‘æµå‘
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['super_large_net_inflow'],
            mode='lines',
            name="è¶…å¤§å•",
            line=dict(color='darkred')
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['large_net_inflow'],
            mode='lines',
            name="å¤§å•",
            line=dict(color='red')
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['medium_net_inflow'],
            mode='lines',
            name="ä¸­å•",
            line=dict(color='purple')
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=flow_history['timestamp'],
            y=flow_history['small_net_inflow'],
            mode='lines',
            name="å°å•",
            line=dict(color='blue')
        ),
        row=2, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_trace(
        go.Scatter(
            x=[flow_history['timestamp'].min(), flow_history['timestamp'].max()],
            y=[0, 0],
            mode='lines',
            line=dict(color='black', dash='dash'),
            showlegend=False
        ),
        row=2, col=1
    )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title="å®æ—¶èµ„é‡‘æµå‘åˆ†æ",
        height=600,
        xaxis_rangeslider_visible=False,
        xaxis=dict(
            rangebreaks=[
                dict(bounds=["sat", "mon"]),  # éšè—å‘¨æœ«
                dict(bounds=[16, 9], pattern="hour")  # éšè—éäº¤æ˜“æ—¶é—´
            ]
        )
    )
    
    # æ›´æ–°yè½´æ ‡é¢˜
    fig.update_yaxes(title_text="å‡€æµå…¥(ä¸‡å…ƒ)", row=1, col=1)
    fig.update_yaxes(title_text="å‡€æµå…¥(ä¸‡å…ƒ)", row=2, col=1)
    
    return fig

# åˆ›å»ºç´¯è®¡èµ„é‡‘æµå‘æŸ±çŠ¶å›¾
def create_flow_summary_chart(flow_history):
    if flow_history.empty:
        return go.Figure()
    
    # è®¡ç®—ç´¯è®¡èµ„é‡‘æµå…¥
    summary = {
        'ä¸»åŠ›èµ„é‡‘': flow_history['main_net_inflow'].sum(),
        'æ•£æˆ·èµ„é‡‘': flow_history['retail_net_inflow'].sum(),
        'è¶…å¤§å•': flow_history['super_large_net_inflow'].sum(),
        'å¤§å•': flow_history['large_net_inflow'].sum(),
        'ä¸­å•': flow_history['medium_net_inflow'].sum(),
        'å°å•': flow_history['small_net_inflow'].sum()
    }
    
    # åˆ›å»ºæŸ±çŠ¶å›¾
    categories = list(summary.keys())
    values = list(summary.values())
    colors = ['red', 'blue', 'darkred', 'red', 'purple', 'blue']
    
    # æ ¹æ®æ­£è´Ÿå€¼è®¾ç½®é¢œè‰²
    bar_colors = ['red' if v >= 0 else 'green' for v in values]
    
    fig = go.Figure()
    fig.add_trace(
        go.Bar(
            x=categories,
            y=values,
            marker_color=bar_colors,
            text=[f"{v:.2f}ä¸‡" for v in values],
            textposition='auto'
        )
    )
    
    fig.update_layout(
        title="ç´¯è®¡èµ„é‡‘æµå‘æ±‡æ€»(ä¸‡å…ƒ)",
        height=400,
        yaxis_title="ç´¯è®¡å‡€æµå…¥(ä¸‡å…ƒ)"
    )
    
    return fig
    
# ä¸»åº”ç”¨é€»è¾‘
def main():
    # è·å–è‚¡ç¥¨åç§°
    stock_name = get_stock_name(stock_code)
    
    # åˆ›å»ºæ ‡é¢˜
    st.header(f"{stock_name}({stock_code}) å®æ—¶è¡Œæƒ…ä¸èµ„é‡‘æµå‘")
    
    # åˆ›å»ºå®¹å™¨è¿›è¡Œå®æ—¶æ›´æ–°
    price_container = st.container()
    col1, col2 = st.columns(2)
    flow_container = col1.container()
    summary_container = col2.container()
    
    # æ˜¾ç¤ºå®æ—¶æ•°æ®çš„å®¹å™¨
    info_container = st.container()
    
    # åˆ›å»ºå ä½å›¾è¡¨
    if 'chart_iteration' not in st.session_state:
        st.session_state.chart_iteration = 0
    
    # ä¸»å¾ªç¯
    while is_running:
        try:
            # å¢åŠ è¿­ä»£è®¡æ•°
            st.session_state.chart_iteration += 1
            current_iter = st.session_state.chart_iteration
            
            # è·å–å®æ—¶æ•°æ®
            quote_data = get_eastmoney_realtime_quote(stock_code)
            flow_data = get_eastmoney_capital_flow(stock_code)
            
            # å¤„ç†æ•°æ®
            price_info = process_quote_data(quote_data)
            flow_info = process_flow_data(flow_data)
            
            # æ›´æ–°å†å²æ•°æ®
            price_history, flow_history = update_historical_data(price_info, flow_info)
            
            # å®æ—¶æ•°æ®å±•ç¤º
            with info_container:
                if price_info:
                    cols = st.columns(5)
                    cols[0].metric("å½“å‰ä»·", f"{price_info['price']:.2f}", f"{price_info['change_percent']:.2f}%")
                    cols[1].metric("æ¶¨è·Œé¢", f"{price_info['change']:.2f}")
                    cols[2].metric("æˆäº¤é‡", f"{price_info['volume']:.0f}æ‰‹")
                    cols[3].metric("æˆäº¤é¢", f"{price_info['amount']:.2f}ä¸‡")
                    cols[4].metric("æ›´æ–°æ—¶é—´", datetime.now().strftime("%H:%M:%S"))
                
                if flow_info:
                    cols = st.columns(3)
                    cols[0].metric("ä¸»åŠ›å‡€æµå…¥", f"{flow_info['main_net_inflow']:.2f}ä¸‡")
                    cols[1].metric("æ•£æˆ·å‡€æµå…¥", f"{flow_info['retail_net_inflow']:.2f}ä¸‡")
                    cols[2].metric("è¶…å¤§å•å‡€æµå…¥", f"{flow_info['super_large_net_inflow']:.2f}ä¸‡")
            
            # æ›´æ–°å›¾è¡¨ï¼Œä¸ºæ¯ä¸ªå›¾è¡¨æä¾›å”¯ä¸€key
            with price_container:
                price_chart = create_price_chart(price_history)
                st.plotly_chart(price_chart, use_container_width=True, key=f"price_chart_{current_iter}")
            
            with flow_container:
                flow_chart = create_flow_chart(flow_history)
                st.plotly_chart(flow_chart, use_container_width=True, key=f"flow_chart_{current_iter}")
            
            with summary_container:
                summary_chart = create_flow_summary_chart(flow_history)
                st.plotly_chart(summary_chart, use_container_width=True, key=f"summary_chart_{current_iter}")
            
            # ä¼‘çœ æŒ‡å®šæ—¶é—´
            time.sleep(update_interval)
            
        except Exception as e:
            st.error(f"æ•°æ®æ›´æ–°å‡ºé”™: {str(e)}")
            time.sleep(update_interval)
            continue

if __name__ == "__main__":
    main() 